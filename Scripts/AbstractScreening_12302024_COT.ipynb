{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leveraging LLMs for Abstract Screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/LLMAbstract_YCLiu/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, BertModel\n",
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_10 = pd.read_csv('./Dataset/CD008874_train_10_12302024.csv',\n",
    "                        header = 0,\n",
    "                        skiprows = 0)\n",
    "\n",
    "train_20 = pd.read_csv('./Dataset/CD008874_train_20_12302024.csv',\n",
    "                        header = 0,\n",
    "                        skiprows = 0)\n",
    "\n",
    "train_40 = pd.read_csv('./Dataset/CD008874_train_40_12302024.csv',\n",
    "                        header = 0,\n",
    "                        skiprows = 0)\n",
    "\n",
    "dev = pd.read_csv('./Dataset/CD008874_dev_200_12302024.csv',\n",
    "                        header = 0,\n",
    "                        skiprows = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetInput(row):\n",
    "    output = '\"\"\" ### Title '\n",
    "    output += row['title']\n",
    "    output += ' ### Abstract '\n",
    "    output += row['abstract']\n",
    "    output += '\"\"\"'\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_10['Input'] = train_10.apply(lambda row: GetInput(row), axis=1)  \n",
    "train_20['Input'] = train_20.apply(lambda row: GetInput(row), axis=1)  \n",
    "train_40['Input'] = train_40.apply(lambda row: GetInput(row), axis=1)  \n",
    "dev['Input'] = dev.apply(lambda row: GetInput(row), axis=1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load BERT tokenizer (uncased)\n",
    "transformer_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(transformer_name)\n",
    "\n",
    "# load pretrained BERT model\n",
    "model = BertModel.from_pretrained(transformer_name)\n",
    "\n",
    "# assign device (cuda if possible)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# load to device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBertCls(text):\n",
    "  '''\n",
    "  this function takes the following input:\n",
    "  text to be represented by the BERT CLS token\n",
    "  and gives the following output:\n",
    "  a numpy array representing the text\n",
    "  '''\n",
    "  tok_text = tokenizer(text[:512],\n",
    "                       return_tensors='pt').to(device)\n",
    "  mod_output = model(**tok_text,\n",
    "                     output_hidden_states=True)\n",
    "  last_hidden_states = mod_output.hidden_states[-1]\n",
    "  return last_hidden_states[:,0,:].cpu().detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column with cls representation of document\n",
    "train_10['BERT_cls'] = train_10['Input'].apply(getBertCls)\n",
    "train_20['BERT_cls'] = train_20['Input'].apply(getBertCls)\n",
    "train_40['BERT_cls'] = train_40['Input'].apply(getBertCls)\n",
    "dev['BERT_cls'] = dev['Input'].apply(getBertCls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calCosSim(emb1, emb2):\n",
    "  '''\n",
    "  return the cosine similarity of the\n",
    "  2 input numpy array\n",
    "  '''\n",
    "  result = emb1 @ emb2.T\n",
    "  result /= (np.linalg.norm(emb1)*np.linalg.norm(emb2))\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPosExample_train10(row):\n",
    "    emb = row['BERT_cls']\n",
    "    PosExamples = train_10[train_10['Include_cont'] == 1].copy()\n",
    "    PMID = row['PMID']\n",
    "    PosExamples = PosExamples[PosExamples['PMID'] != PMID].copy()\n",
    "    PosExamples['Sim'] = PosExamples['BERT_cls'].apply(lambda x: calCosSim(emb, x))\n",
    "    sim = PosExamples['Sim']\n",
    "    \n",
    "    return PosExamples.iloc[np.argmax(sim)]['Input']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPosExample_train20(row):\n",
    "    emb = row['BERT_cls']\n",
    "    PosExamples = train_20[train_20['Include_cont'] == 1].copy()\n",
    "    PMID = row['PMID']\n",
    "    PosExamples = PosExamples[PosExamples['PMID'] != PMID].copy()\n",
    "    PosExamples['Sim'] = PosExamples['BERT_cls'].apply(lambda x: calCosSim(emb, x))\n",
    "    sim = PosExamples['Sim']\n",
    "    \n",
    "    return PosExamples.iloc[np.argmax(sim)]['Input']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPosExample_train40(row):\n",
    "    emb = row['BERT_cls']\n",
    "    PosExamples = train_40[train_40['Include_cont'] == 1].copy()\n",
    "    PMID = row['PMID']\n",
    "    PosExamples = PosExamples[PosExamples['PMID'] != PMID].copy()\n",
    "    PosExamples['Sim'] = PosExamples['BERT_cls'].apply(lambda x: calCosSim(emb, x))\n",
    "    sim = PosExamples['Sim']\n",
    "    \n",
    "    return PosExamples.iloc[np.argmax(sim)]['Input']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_10['PosExample_10'] = train_10.apply(GetPosExample_train10, axis=1)\n",
    "dev['PosExample_10'] = dev.apply(GetPosExample_train10, axis=1)\n",
    "\n",
    "train_20['PosExample_20'] = train_20.apply(GetPosExample_train20, axis=1)\n",
    "dev['PosExample_20'] = dev.apply(GetPosExample_train20, axis=1)\n",
    "\n",
    "\n",
    "train_40['PosExample_40'] = train_40.apply(GetPosExample_train40, axis=1)\n",
    "dev['PosExample_40'] = dev.apply(GetPosExample_train40, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get key\n",
    "load_dotenv()\n",
    "client = OpenAI(\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "## Instruction\n",
    "\n",
    "You will take the role of a scientific research reviewer to evaluate titles and abstracts for further assessment \\\n",
    "concerning the systematic review study titled \\\n",
    "\"Airway physical examination tests for detection of difficult airway management in apparently normal adult patients\" \\\n",
    "Please generate a relevance score for the title and abstract in triple quotes based on the following inclusion criteria. \\\n",
    "The relevance score should be between 0 (completely irrelevant) to 100 (perfectly relevant). \\\n",
    "You will need to review the abstract and apply the inclusion criteria step by step to determine if it meets the requirements. \\\n",
    "Please think through your decision-making process and explain each step.\n",
    "\n",
    "### Inclusion Criteria\n",
    "\n",
    "1. Study Type: Full-text diagnostic test accuracy studies.\n",
    "\n",
    "2. Index Tests (one or more):\n",
    "   - Mallampati test\n",
    "   - Modified Mallampati test\n",
    "   - Wilson risk score\n",
    "   - Thyromental distance\n",
    "   - Sternomental distance\n",
    "   - Mouth opening test\n",
    "   - Upper lip bite test\n",
    "\n",
    "3. Target Condition: Difficult airway, defined by:\n",
    "   - Difficult face mask ventilation\n",
    "   - Difficult laryngoscopy\n",
    "   - Difficult tracheal intubation\n",
    "   - Failed intubation\n",
    "\n",
    "4. Participants:\n",
    "   - Adult patients\n",
    "   - No obvious airway abnormalities\n",
    "   - Standard laryngoscope used\n",
    "   - Standard tracheal tube used\n",
    "\n",
    "### Process\n",
    "\n",
    "For each abstract, follow this thought process:\n",
    "\n",
    "1. **Step 1: Study Type** – Is the study a diagnostic test accuracy study?\n",
    "2. **Step 2: Index Test(s)** – Does the abstract mention one or more of the index tests listed above?\n",
    "3. **Step 3: Target Condition** – Does the abstract involve a target condition of difficult airway, as defined by the criteria?\n",
    "4. **Step 4: Participants** – Are the participants adult patients without obvious airway abnormalities, \\\n",
    "and were standard laryngoscopy and tracheal tube used?\n",
    "\n",
    "After evaluating the abstract based on these steps, determine if it should be included in the review.\n",
    "\n",
    "### Output\n",
    "\n",
    "Expected output format:\n",
    "\n",
    "{{\n",
    "    \"RelevanceScore\": int from 0 to 100,\n",
    "    \"Reason\": \"Brief explanation of the Relevance Score based on inclusion criteria\"\n",
    "}}\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRelScore_10(row):\n",
    "    txt = row['Input']\n",
    "    example = row['PosExample_10']\n",
    "    prompt_used = prompt + f'\\n\\n### Example \\n\\n Below is an example delimited by triple quotes that should definitely be included: \\n \"\"\"{example}\"\"\"'\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt_used},\n",
    "        {\"role\": \"user\", \"content\": txt}\n",
    "        ]\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_10['Results_10'] = train_10.apply(getRelScore_10, axis=1)\n",
    "dev['Results_10'] = dev.apply(getRelScore_10, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRelScore_20(row):\n",
    "    txt = row['Input']\n",
    "    example = row['PosExample_20']\n",
    "    prompt_used = prompt + f'\\n\\n### Example \\n\\n Below is an example delimited by triple quotes that should definitely be included: \\n \"\"\"{example}\"\"\"'\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt_used},\n",
    "        {\"role\": \"user\", \"content\": txt}\n",
    "        ]\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_20['Results_20'] = train_20.apply(getRelScore_20, axis=1)\n",
    "dev['Results_20'] = dev.apply(getRelScore_20, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRelScore_40(row):\n",
    "    txt = row['Input']\n",
    "    example = row['PosExample_40']\n",
    "    prompt_used = prompt + f'\\n\\n### Example \\n\\n Below is an example delimited by triple quotes that should definitely be included: \\n \"\"\"{example}\"\"\"'\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt_used},\n",
    "        {\"role\": \"user\", \"content\": txt}\n",
    "        ]\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_40['Results_40'] = train_40.apply(getRelScore_40, axis=1)\n",
    "dev['Results_40'] = dev.apply(getRelScore_40, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parseScore(res):\n",
    "    try:\n",
    "        js = res[1:-1]\n",
    "        \n",
    "        results = json.loads(js)\n",
    "        \n",
    "        return results[\"RelevanceScore\"]\n",
    "    except:\n",
    "        try:\n",
    "            js = res[8:-4]\n",
    "        \n",
    "            results = json.loads(js)\n",
    "        \n",
    "            return results[\"RelevanceScore\"]\n",
    "        except:\n",
    "            return \"Error\"\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def parseReason(res):\n",
    "    try:\n",
    "        js = res[1:-1]\n",
    "        \n",
    "        results = json.loads(js)\n",
    "        \n",
    "        return results[\"Reason\"]\n",
    "    except:\n",
    "        try:\n",
    "            js = res[8:-4]\n",
    "        \n",
    "            results = json.loads(js)\n",
    "        \n",
    "            return results[\"Reason\"]\n",
    "        except:\n",
    "            return \"Error\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_10['RelevanceScore'] = train_10['Results_10'].apply(parseScore)    \n",
    "train_10['Reason'] = train_10['Results_10'].apply(parseReason)\n",
    "train_10.to_csv('./Dataset/DynamicOneShotCoT_Training_10_12302024.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_20['RelevanceScore'] = train_20['Results_20'].apply(parseScore)    \n",
    "train_20['Reason'] = train_20['Results_20'].apply(parseReason)\n",
    "train_20.to_csv('./Dataset/DynamicOneShotCoT_Training_20_12302024.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_40['RelevanceScore'] = train_40['Results_40'].apply(parseScore)    \n",
    "train_40['Reason'] = train_40['Results_40'].apply(parseReason)\n",
    "train_40.to_csv('./Dataset/DynamicOneShotCoT_Training_40_12302024.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dev['RelevanceScore_10'] = dev['Results_10'].apply(parseScore)    \n",
    "dev['Reason_10'] = dev['Results_10'].apply(parseReason)\n",
    "\n",
    "dev['RelevanceScore_20'] = dev['Results_20'].apply(parseScore)    \n",
    "dev['Reason_20'] = dev['Results_20'].apply(parseReason)\n",
    "\n",
    "dev['RelevanceScore_40'] = dev['Results_40'].apply(parseScore)    \n",
    "dev['Reason_40'] = dev['Results_40'].apply(parseReason)\n",
    "\n",
    "dev.to_csv('./Dataset/DynamicOneShotCoT_dev_12302024.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
